{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t, expon\n",
    "\n",
    "class Data_generator:\n",
    "    def __init__(self, _alpha_r=0, _beta_r=1, _d=1, _alpha_u=0, _beta_u=1, _gamma=1, _theta=0, __lambda=1):\n",
    "        self.alpha_r = _alpha_r\n",
    "        self.beta_r = _beta_r\n",
    "        self.d = _d\n",
    "        self.alpha_u = _alpha_u\n",
    "        self.beta_u = _beta_u\n",
    "        self.gamma = _gamma\n",
    "        self.theta = _theta\n",
    "        self._lambda = __lambda\n",
    "\n",
    "    def gen_data(self, n=1000, T=100):\n",
    "        r=np.zeros((T,n)) #r yield\n",
    "        eps=np.zeros(n)\n",
    "        u=np.zeros(n)\n",
    "        for i in range(T):\n",
    "            u = self.alpha_u+self.beta_u*u+self.gamma*eps**2+self.theta*np.where(eps<0,eps**2,0)+np.random.exponential(scale=1/self._lambda,size=n)\n",
    "            eps=np.random.standard_t(df=self.d, size=n)*np.sqrt(u)\n",
    "            r[i]=self.alpha_r+self.beta_r*u+eps\n",
    "        return r\n",
    "    \n",
    "    def gen_data_full(self, n=1000, T=100):\n",
    "        r=np.zeros((T,n)) #r yield\n",
    "        eps_list=np.zeros((T,n))\n",
    "        u_list=np.zeros((T,n))\n",
    "        u=np.zeros(n)\n",
    "        eps=np.zeros(n)\n",
    "        for i in range(T):\n",
    "            u = self.alpha_u+self.beta_u*u+self.gamma*eps**2+self.theta*np.where(eps<0,eps**2,0)+np.random.exponential(scale=1/self._lambda,size=n)\n",
    "            eps=np.random.standard_t(df=self.d, size=n)*np.sqrt(u)\n",
    "            u_list[i]=u\n",
    "            eps_list[i]=eps\n",
    "            r[i]=self.alpha_r+self.beta_r*u+eps\n",
    "        return r, u_list, eps_list\n",
    "\n",
    "def updaterr(r_t, eps_t, r_t1, eps_t1, alpha_r, beta_r, d, alpha_u, beta_u, gamma, theta, _lambda):\n",
    "    u_t1 = (r_t1 - alpha_r - eps_t1) / beta_r\n",
    "    w_t = alpha_u + beta_u * u_t1 + gamma * eps_t1 ** 2 + theta * (eps_t1 < 0) * eps_t1 ** 2\n",
    "    nu_t = eps_t * np.sqrt(beta_r / (r_t - eps_t - alpha_r))\n",
    "    eta_t = (r_t - eps_t - alpha_r) / beta_r - w_t\n",
    "    p = t.pdf(nu_t, d) * expon.pdf(eta_t, scale=1 / _lambda) / np.sqrt(beta_r * (r_t - eps_t - alpha_r))\n",
    "    return p\n",
    "\n",
    "class TEST_SAMPLER:\n",
    "    \"\"\"test sampler\"\"\"\n",
    "    samples = []\n",
    "    def __init__(self, T, params):\n",
    "        self.alpha_r, self.beta_r, self.d, self.alpha_u, self.beta_u,self.gamma, self.theta, self._lambda = params\n",
    "        self.params = params\n",
    "        self.T = T \n",
    "        \n",
    "    def sample(self, sample_num:int, r):\n",
    "        samples = np.zeros((self.T, sample_num))\n",
    "        weights = np.ones(sample_num)\n",
    "        for i in range(1, self.T): \n",
    "            for j in range(sample_num):\n",
    "                samples[i][j] = self.policy(r[i][j], r[i-1][j], samples[i-1][j])\n",
    "                weights[j] *= updaterr(r[i][j], samples[i][j], r[i-1][j], samples[i-1][j], *self.params)/self.policy_density(r[i][j], samples[i][j], r[i-1][j], samples[i-1][j])\n",
    "        weights *= sample_num/np.sum(weights)\n",
    "        return samples, weights\n",
    "\n",
    "    def policy(self, rt, rt1, et1):\n",
    "        \"\"\"sampling policy\"\"\"\n",
    "        return rt - self.alpha_r - expon.rvs(scale=0.8)\n",
    "\n",
    "    def policy_density(self, rt, et, rt1, et1): \n",
    "        \"\"\"pdf of policy\"\"\"\n",
    "        return  expon.pdf(rt - self.alpha_r - et, scale=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class EM:\n",
    "    def __init__(self, T, _alpha_r=0, _beta_r=1, _d=1, _alpha_u=0, _beta_u=1, _gamma=1, _theta=0, __lambda=1):\n",
    "        self.alpha_r = torch.tensor(_alpha_r, dtype=torch.float32, requires_grad=True)\n",
    "        self.beta_r = torch.tensor(_beta_r, dtype=torch.float32, requires_grad=True)\n",
    "        self.alpha_u = torch.tensor(_alpha_u, dtype=torch.float32, requires_grad=True)\n",
    "        self.beta_u = torch.tensor(_beta_u, dtype=torch.float32, requires_grad=True)\n",
    "        self.gamma = torch.tensor(_gamma, dtype=torch.float32, requires_grad=True)\n",
    "        self.theta = torch.tensor(_theta, dtype=torch.float32, requires_grad=True)\n",
    "        self._lambda = torch.tensor(__lambda, dtype=torch.float32, requires_grad=True)\n",
    "        self.d = torch.tensor(_d, dtype=torch.float32, requires_grad=True)\n",
    "        self.parameters=[self.alpha_r, self.beta_r, self.alpha_u, self.beta_u, self.gamma, self.theta, self._lambda, self.d]\n",
    "        self.T=T\n",
    "        self.load_data()\n",
    "    def call_sampler(self,n):\n",
    "        #remember to add .item() at final version\n",
    "        return torch.randn(10), torch.randn(10,self.T)\n",
    "        #The below is currently not working\n",
    "        params=(self.alpha_r.item(), self.beta_r.item(), self.d.item(), self.alpha_u.item(), self.beta_u.item(), self.gamma.item(), self.theta.item(), self._lambda.item())\n",
    "        sampler = TEST_SAMPLER(self.T, params)\n",
    "        samples, weights=sampler.sample(n, self.r)\n",
    "        return weights,samples.T\n",
    "    def load_data(self):\n",
    "        DG = Data_generator(0.2, 0.2, 6.0, 0.6, 0.4, 0.1, 0.02, 2.5)\n",
    "        self.r=torch.tensor(DG.gen_data(1, self.T))\n",
    "    def upd_param(self,lr=0.01):\n",
    "        with torch.no_grad():\n",
    "            for param in self.parameters:\n",
    "                param -= lr * param.grad #check + or -\n",
    "                param.grad.zero_()\n",
    "    def singularlikelihood(self,epsilon):\n",
    "        #calculate log-likelihood of each set of epsilon, (n,T) -> (n,)\n",
    "        return torch.randn(epsilon.shape[0])\n",
    "    def log_total(self):\n",
    "        n=10\n",
    "        weights,epsilon=self.call_sampler(n)\n",
    "        likelihood=self.singularlikelihood(epsilon)\n",
    "        normed=likelihood-torch.sum(likelihood).item()/n+torch.log(weights) #item for removing normalization from gradients\n",
    "        return torch.log(torch.sum(torch.exp(normed)))\n",
    "    def optimize(self,num_steps=10):\n",
    "        for _ in range(num_steps):\n",
    "            likelihood=self.log_total()\n",
    "            likelihood.backward()\n",
    "            self.upd_param(lr=0.01)\n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "EM_sampler=EM(10,0.2, 0.2, 6.0, 0.6, 0.4, 0.1, 0.02, 2.5)\n",
    "EM_sampler.r.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
